<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on felladog</title><link>https://utsavdarlami.github.io/blogs/categories/machine-learning/</link><description>Recent content in machine learning on felladog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 04 Jun 2021 19:53:00 +0545</lastBuildDate><atom:link href="https://utsavdarlami.github.io/blogs/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>concept learning</title><link>https://utsavdarlami.github.io/blogs/notes/2021-06-04--14-08-26z--concept_learning/</link><pubDate>Fri, 04 Jun 2021 19:53:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/2021-06-04--14-08-26z--concept_learning/</guid><description>References : Reading: Tom Mitchell Lectures slides of chapter 2 Tom Mitchell, Machine Learning Chapter 2 To Read: Candidate elimination algorithm with an example Questions : Inferring boolean valued function from training examples of its input and outputs. A problem of searching through a predefined space of potential hypotheses for the hypothesis that best fits the training examples Example Traget concept or function: Concept or function to be learned. For our example - &amp;ldquo;days on which &amp;ldquo;A&amp;rdquo; can enjoy water sport&amp;rdquo;, EnjoySport Denoted by \(c\) c can be any boolean valued function defined over the instances X; \( c : X \rightarrow \{ 0,1 \} \) Instances The set of items over which the concept is defined.</description></item><item><title>Inductive Bias</title><link>https://utsavdarlami.github.io/blogs/notes/2021-06-03--11-07-01z--inductive_bias/</link><pubDate>Thu, 03 Jun 2021 16:52:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/2021-06-03--11-07-01z--inductive_bias/</guid><description>References :
Reading: Tom Mitchell Lectures slides of chapter 2 Tom Mitchell, Machine Learning Chapter 2 To Read: https://en.wikipedia.org/wiki/Inductive%5Fbias Questions :
The inductive bias of a learning algorithm is the set of assumptions that the learner uses to predict outputs given inputs that it has not encountered.
Consider a concept learning algorithm L for the set of instances X. Let c be an arbitrary concept defined over X, and let \(D_c\) = {&amp;lt;x,c(x)&amp;gt;} be an arbitrary set of training examples of c.</description></item><item><title>decision tree</title><link>https://utsavdarlami.github.io/blogs/notes/2021-06-03--11-01-27z--decision_tree/</link><pubDate>Thu, 03 Jun 2021 16:46:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/2021-06-03--11-01-27z--decision_tree/</guid><description>References :
Reading : Tom Mitchell Lectures slides of chapter 3 Tom Mitchell, Machine Learning Chapter 3 ID3 algorithm complete solution Reddit Post Link Drive Pdf Link To Read : Chapter 3 — Decision Tree Learning — Part 1 Questions :
Approximating discrete-valued fucntions robust to noisy data capable of learning disjunctive expressions search a completely expressive hypothesis space and thus avoid the difficulties of restricted hypothesis spaces. Representation Decision trees classify instances by sorting them down the tree from the root to some leaf node each leaf node assigns a classification each interal node specifies a test of some attributes of the instances each branch descending from a node corresponds to one of the possible values of the attribute represented by that node.</description></item><item><title>regularization</title><link>https://utsavdarlami.github.io/blogs/notes/2021-05-26--11-28-39z--regularization/</link><pubDate>Wed, 26 May 2021 17:13:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/2021-05-26--11-28-39z--regularization/</guid><description>References :
To read: https://www.wikiwand.com/en/Regularization%5F(mathematics) https://www.wikiwand.com/en/Early%5Fstopping Questions :
In machine learning and regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.
Early Stopping Form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner&amp;rsquo;s performance on validation set.</description></item><item><title>entropy</title><link>https://utsavdarlami.github.io/blogs/notes/2021-03-06--03-56-06z--entropy/</link><pubDate>Sat, 06 Mar 2021 09:41:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/2021-03-06--03-56-06z--entropy/</guid><description>References :
https://www.wikiwand.com/en/Entropy%5F(information%5Ftheory) Entropy in image, scikit-image [3] https://bricaud.github.io/personal-blog/entropy-in-decision-trees/
Questions :
What is the point of entropy in decision tree? Entropy is a measure of disorder. A high entropy is essentially saying that the data is scattered around while a low entropy means that nearly all the data is the same.
In information theory, information entropy is the log-base-2 of the number of possible outcomes for a message.
\(- \log_{2} p\) Based on our dataset we can say</description></item><item><title>ML Model Evaluation</title><link>https://utsavdarlami.github.io/blogs/notes/20210224162319-model_evaluations_score/</link><pubDate>Wed, 24 Feb 2021 16:23:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/20210224162319-model_evaluations_score/</guid><description>references To Read: https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28 https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin questions ml model evaluation methods
Classfication True Positive (TP) Positive class correctly labeled/predicted False Negative (FN) Positive class incorrectly labeled/predicted False Positive (FP) Negative class incorrectly labeled/predicted True Negative (TN) Negative class correctly labeled/predicted Accuracy It is simply a ratio of correctly predicted observation to the total observations. Accuracy = \(\frac{TP + TN}{TP + TN + FN + FP}\) Precision Precision = \(\frac{True Positive}{True Positive + False Positive}\) From all the postive prediction given by our hypothesis/model how many examples were true positive Recall Recall = \(\frac{True Positive}{True Positive + False Negative}\) From all the postive examples how many examples were correctly classified by our hypothesis/model F1 Score A harmonic mean between recall and precision</description></item><item><title>image segmentation</title><link>https://utsavdarlami.github.io/blogs/notes/20210224161655-image_segmentation/</link><pubDate>Wed, 24 Feb 2021 16:16:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/20210224161655-image_segmentation/</guid><description>references: https://www.youtube.com/watch?v=AZr64OxshLo https://www.youtube.com/watch?v=0FmNxqLFeYo questions : Types of image segmentation Semantic segmentation Instance segmentation Apporaches for segmentation Using Classical Approach Histogram Based Segmentation thresholding Random Walker Segmentation Watershed Segmentation Graph based segmentation &amp;lt;/home/felladog/Downloads/CV_Nptel/W2/DL4CV_Week02_Part05.pdf&amp;gt; https://youtu.be/0HbRnFTOOms?t=680 Using Unsupervised Approach Gaussian Mixture Model Kmeans Clustering Using Deep Learning UNET Image Segmentation Loss/Evaluation Method Problem with other common metrics We need metrics that target pixels in foreground Intersection over union (Jaccard index) sklearn jaccard module</description></item><item><title>machine learning</title><link>https://utsavdarlami.github.io/blogs/notes/20210119123811-machine_learning/</link><pubDate>Sun, 17 Jan 2021 17:28:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/20210119123811-machine_learning/</guid><description>references Reading https://www.cs.cmu.edu/~tom/mlbook.html To Read https://rentruewang.github.io/learning-machine/intro.html https://medium.com/octavian-ai/how-to-get-started-with-machine-learning-on-graphs-7f0795c83763 https://medium.datadriveninvestor.com/3-steps-introduction-to-machine-learning-and-design-of-a-learning-system-bd12b65aa50c https://chrisalbon.com/ Interpretable Machine Learning A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.
Machine learning is a subfield of AI that studies the ability to improve performance based on experience.Some AI systems use machine learning methods to achieve competence, but some do not.</description></item></channel></rss>