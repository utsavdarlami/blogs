+++
title = "xgboost"
author = ["felladog"]
date = 2021-01-18T13:08:00+05:45
tags = ["ensemble", "boosting", "regression", "classfication", "gain"]
categories = ["machine learning"]
draft = false
+++

---

-   publish date : 18 jan 2021
-   review date : 28 feb 2021
-   references :
    -   [XGBoost Part 1 (of 4): Regression](https://www.youtube.com/watch?v=OtD8wVaFm6E)
    -   [XGBoost Part 3 Math Details Stat Quests](https://www.youtube.com/watch?v=ZVFeW798-2I)
-   Questions :
    -   What is log odds, from log odds to probability

---

-   Machine Learning Algorithm for regression and classification problems.


## For Regression {#for-regression}

-   Similarity score =  \\(\frac{ { \text{Sum of residuals, Squared} } } {\text{number of residuals}+ \lambda} }\\)
-   **Gain** to determine how to split the data (Gain should be high)
-   Gain = \\(Left\_{similarity} + Right\_{similarity} - Root\_{similarity}\\)
-   Pruning the tree by calculating the difference between Gain and the tree complexity Parameter, \\(\gamma\\) (Gamma).
-   Gain - \\(\gamma\\) = if positive then no pruning else prune the tree
-   Calculate the output values for the remaining leaves, Output Value = \\(\frac{ { \text{Sum of residuals} } } {\text{number of residuals}+ \lambda} }\\)
-   \\(\lambda\\) Lambda is the regularization parameter
-   \\(\lambda\\) > 0, results in more pruning, by shrinking the similarity scores and results in smaller output values for the leaves


## For Classification {#for-classification}

-   For Classification Similarity score =  \\(\frac{ { \text{Sum of residuals, Squared} } } {\sum\text{[Previous Probability \* (1 - Prev Probability)]}+ \lambda} }\\)

-   Cover determines the minimum number of Residuals in each leaf.

-   Cover = Similarity Score - \\(\lambda\\)
-   In Classification, Cover = \\(\sum{\text{[Previous Probability \* (Prev Probability - 1)]}\\)
-   In Regression, Cover = \\(\text{Number of Residuals}\\)
-   For Classification Output Value = \\(\frac{ { \text{Sum of residuals} } } {\sum\text{[Previous Probability \* (1- Prev Probability)]}+ \lambda} }\\)


## Mathematical Details {#mathematical-details}

-
