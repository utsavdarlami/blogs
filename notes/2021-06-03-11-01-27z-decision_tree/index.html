<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>decision tree</title><meta name=description content="felladog"><meta name=author content="Utsav Darlami"><link rel="shortcut icon" href=/blogs/img/21-512.png><link rel=stylesheet href=/blogs/css/style.css><link rel=stylesheet href=/blogs/css/syntax.css><link rel=stylesheet href=/blogs/css/toc.css><link rel=stylesheet href=/blogs/katex/katex.min.css><script defer src=/blogs/katex/katex.min.js></script><script defer src=/blogs/katex/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script></head><body><header></header><main><div class=toc><nav id=TableOfContents><ul><li><a href=#representation>Representation</a></li><li><a href=#when-is-decision-tree-suitable>When is Decision Tree suitable ?</a></li><li><a href=#id3>ID3</a><ul><li><a href=#entropy--2021-03-06-03-56-06z-entropy-dot-md><a href=HAHAHUGOSHORTCODE-s1-HBHB>entropy</a></a></li><li><a href=#information-gain>Information gain</a></li><li><a href=#illustrative-example>Illustrative Example</a></li></ul></li><li><a href=#hypothesis-space-search>Hypothesis Space Search</a><ul><li><a href=#limitations-and-capabilities-of-id3>Limitations and Capabilities of ID3</a></li></ul></li><li><a href=#inductive-bias--2021-06-03-11-07-01z-inductive-bias-dot-md><a href=HAHAHUGOSHORTCODE-s10-HBHB>Inductive Bias</a></a></li><li><a href=#restriction-and-preference-biases>Restriction and Preference Biases</a></li><li><a href=#why-prefer-short-hypotheses>Why prefer Short Hypotheses</a></li><li><a href=#issues>Issues</a></li></ul></nav><a href=# class=back-to-top>Back to top</a></div><script src=https://utsavdarlami.github.io/blogs/js/libs/jquery/3.3.1/jquery.slim.min.js></script><script>(function(){var a=$('#TableOfContents'),b;if(a.length>0){b=$(window);function c(){var e=b.scrollTop(),f=$('.body h1, .body h2, .body h3, .body h4, .body h5, .body h6'),c="",d;if(f.each(function(b,a){a=$(a),a.offset().top-10<=e&&(c=a.attr('id'))}),d=a.find('a.current'),d.length==1&&d.eq(0).attr('href')=='#'+c)return!0;d.each(function(b,a){$(a).removeClass('current').siblings('ul').hide()}),a.find('a[href="#'+c+'"]').parentsUntil('#TableOfContents').each(function(b,a){$(a).children('a').addClass('current').siblings('ul').show()})}b.on('scroll',c),$(document).ready(function(){a.find('a').parent('li').find('ul').hide(),c(),document.getElementsByClassName('toc')[0].style.display=''})}})()</script><p align=right><a href=https://utsavdarlami.github.io/>home</a> |
<a href=https://utsavdarlami.github.io/blogs/>blogs</a> |
<a href=https://utsavdarlami.github.io/blogs/notes>notes</a> |
<a href=https://utsavdarlami.github.io/blogs/about>about me</a> |
<a href=https://utsavdarlami.github.io/blogs/tags>tags</a> |
<a href=https://utsavdarlami.github.io/blogs/categories>categories</a> |
<a href=https://utsavdarlami.github.io/blogs/index.xml>feed</a></p><article><h1>decision tree</h1><div style=float:left><time>Created Date : 2021 June 03</time></div><br><div style=float:left><time>Last Modified : 2021 June 06</time></div><hr><div>tags:
<a href=/blogs/tags/entropy>entropy</a>
<a href=/blogs/tags/id3>ID3</a>
<a href=/blogs/tags/information-gain>information gain</a></div><div style=float:left>categories:
<a href=/blogs/categories/machine-learning>machine learning</a></div><div><hr><ul><li><p>References :</p><ul><li>Reading :<ul><li>Tom Mitchell Lectures slides of chapter 3</li><li>Tom Mitchell, Machine Learning Chapter 3</li><li>ID3 algorithm complete solution<ul><li><a href=https://www.reddit.com/r/learnmachinelearning/comments/nmsdhs/i%5Fsolved%5Fa%5Fid3%5Falgorithm%5Fin%5Fmachine%5Flearning/>Reddit Post Link</a></li><li><a href=https://drive.google.com/file/d/1b2ocYqBxl3oX2o0S-dLgbVVNSGGamUel/view>Drive Pdf Link</a></li></ul></li></ul></li><li>To Read :<ul><li><a href=https://medium.com/@pralhad2481/chapter-3-decision-tree-learning-part-1-d0ca2365bb22>Chapter 3 — Decision Tree Learning — Part 1</a></li></ul></li></ul></li><li><p>Questions :</p></li></ul><hr><ul><li>Approximating discrete-valued fucntions</li><li>robust to noisy data</li><li>capable of learning disjunctive expressions</li><li>search a completely expressive hypothesis space and thus avoid the difficulties of restricted hypothesis spaces.</li></ul><h2 id=representation>Representation</h2><ul><li>Decision trees classify instances by sorting them down the tree from the root to some leaf node</li><li>each leaf node assigns a classification</li><li>each interal node specifies a test of some attributes of the instances</li><li>each branch descending from a node corresponds to one of the possible values of the attribute represented by that node.</li></ul><figure><img src=/ox-hugo/dt_1.png></figure><ul><li>For the instance &lt;Outlook = Sunny, Temperature = Hot, Humidity = High, Wind=Strong><ul><li>PlayTennis = no</li></ul></li><li>In general, decision trees represent a disjunction of conjunctions of constraints on the attribute values of instances.</li><li>Each path from the tree root to a leaf corresponds to a conjunction of attribute tests, and the tree itself to a disjunction of these conjunctions.</li></ul><h2 id=when-is-decision-tree-suitable>When is Decision Tree suitable ?</h2><ol><li>Instances are represented by many attribute value pairs.</li><li>The target function output may be<ul><li>discrete-valued,</li><li>with certain extension can be used for real-valued output</li></ul></li><li>The training examples may contain noises/errors</li><li>Disjunctive descriptions may be required</li><li>The training data may contain missing attribute values</li></ol><h2 id=id3>ID3</h2><ul><li>Basic algorithm for learning decision tree.</li><li>&ldquo;Which attribute should be tested at the root of the tree?&rdquo;<ul><li>Which attribute to test at each node in the tree</li></ul></li></ul><h3 id=entropy--2021-03-06-03-56-06z-entropy-dot-md><a href=/blogs/notes/2021-03-06-03-56-06z-entropy/>entropy</a></h3><ul><li>Given a collection 5, containing positive and negative examples of some target concept, the entropy of S relative to this boolean classification is<ul><li>\( Entropy(S) = - p_{\oplus} log_2 p_{\oplus} - p_{\ominus} log_2 p_{\ominus} \)</li><li>where, \(p_{\oplus}\) is the proportion of positive examples in S and,</li><li>\(p_{\ominus}\) is the proportion of negative examples in S.</li></ul></li><li>Example,<ul><li>Entropy([9+, 5-]) = 0.940</li></ul></li><li>Entropy is<ul><li>0 if all members of S belong to the same class.</li><li>1 when the collection contains an equal number of positive and negative examples.</li></ul></li></ul><figure><img src=/ox-hugo/dt_ent1.png></figure><ul><li>If the target attribute can take on c different values, then the entropy of S relative to this c-wise classification is defined as<ul><li>\( Entropy(S) = \sum_{i=1}^{c} - p_i log_2 p_i \) , where \(p_i\), is the proportion of S belonging to class i.</li></ul></li></ul><h3 id=information-gain>Information gain</h3><ul><li>measures how well a given attribute separates the training examples according to their target classification.</li><li>ID3 uses it to select attributes among the candidate attributes at each step while growing the tree.</li><li>It is the expected reduction in the entropy caused by partitioning the examples based on the attributes</li><li>the information gain, Gain(S, A) of an attribute A, relative to a collection of examples S, is defined as<ul><li>\( Gain(S,A) = Entropy(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} Entropy(S_v) \)</li><li>where, Values(A) is the set of all possible values for attribute A,</li><li>\(S_v\) is the subset of S for which attribute A has value v (i.e., \( S_v = \{s \in S|A(s) = v\}) \).</li><li>the first term is just the entropy of the original collection S,</li><li>and the second term is the expected value of the entropy after S is partitioned using attribute A.</li></ul></li><li>Gain(S, A) is<ul><li>the information provided about the target function value, given the value of some other attribute A.</li><li>the number of bits saved when encoding the target value of an arbitrary member of S, by knowing the value of attribute A.</li></ul></li></ul><h3 id=illustrative-example>Illustrative Example</h3><figure><img src=/ox-hugo/dt_eg.png></figure><figure><img src=/ox-hugo/dt_root.png></figure><ul><li>The information gain values for all four attributes are<ul><li>Gain(S, Outlook) = 0.246</li><li>Gain(S, Humidity) = 0.151</li><li>Gain(S, Wind) = 0.048</li><li>Gain(S, Temperature) = 0.029</li></ul></li></ul><figure><img src=/ox-hugo/dt_final_eg.png></figure><ul><li>ID3 algorithm complete solution<ul><li><a href=https://www.reddit.com/r/learnmachinelearning/comments/nmsdhs/i%5Fsolved%5Fa%5Fid3%5Falgorithm%5Fin%5Fmachine%5Flearning/>Reddit Post Link</a></li></ul></li></ul><h2 id=hypothesis-space-search>Hypothesis Space Search</h2><ul><li>ID3 performs a simple-to-complex, hill-climbing search through hypothesis space,<ul><li>beginning with the empty tree,</li><li>then considering progressively more elaborate hypotheses in search of decision tree that correctly classifies the training data.</li></ul></li><li>hill-climbing search is guided information gain measure.</li></ul><figure><img src=/ox-hugo/id3_search.png></figure><h3 id=limitations-and-capabilities-of-id3>Limitations and Capabilities of ID3</h3><ul><li>ID3&rsquo;s hypothesis space of all decision trees is a complete space of finite discrete-valued functions, relative to the available attributes.<ul><li>Thus, avoids one of the major risks of methods that search incomplete hypothesis spaces(such as methods that consider only conjunctive hypotheses): that the hypothesis space might not contain the target function.</li></ul></li><li>Maintains only a single current hypothesis as it searches through the space of decision trees.<ul><li>wheras, <a href=/blogs/notes/2021-06-04-14-08-26z-concept_learning/>Candidate-Elimination Learning Algorithm</a>, which maintains the set of all hypotheses consistent with the available training examples.</li><li>it does not have the ability to determine how many alternative decision trees are consistent with the available training data,</li></ul></li><li>ID3 in its pure form performs no backtracking in its search.<ul><li>usually risks of hill-climbing search without backtracking: converging to locally optimal solutions that are not globally optimal.</li></ul></li><li>ID3 uses all training examples at each step in the search to make statistically based decisions regarding how to refine its current hypothesis.<ul><li>contrasts with methods that make decisions incrementally, based on individual training examples (e.g., <a href=/blogs/notes/2021-06-04-14-08-26z-concept_learning/>Find-S</a> or <a href=/blogs/notes/2021-06-04-14-08-26z-concept_learning/>Candidate-Elimination Learning Algorithm</a>)</li><li>Advantage is that the resulting search is much less sensitive to errors in individual training examples.</li></ul></li></ul><h2 id=inductive-bias--2021-06-03-11-07-01z-inductive-bias-dot-md><a href=/blogs/notes/2021-06-03-11-07-01z-inductive_bias/>Inductive Bias</a></h2><ul><li><p>the ID3 search strategy</p><ol><li>selects in favor of shorter trees over longer ones, and</li><li>selects trees that place the attributes with highest information gain closest to the root.</li></ol></li><li><p><strong>Approximate inductive bias of ID3</strong>:</p><ul><li>Shorter trees are preferred over larger trees.</li></ul></li><li><p>BFS-ID3, Breadth First Search for ID3</p></li><li><p><strong>A closer approximation to the inductive bias of ID3</strong>:</p><ul><li>Shorter trees are preferred over longer trees. Trees that place high information gain attributes close to the root are preferred over those that do not.</li></ul></li></ul><h2 id=restriction-and-preference-biases>Restriction and Preference Biases</h2><ul><li>the inductive bias of<ul><li>ID3 follows from its <strong>search strategy</strong>,</li><li>Candidate-Elimination algorithm follows from the definition of its <strong>search space</strong>.</li></ul></li><li>ID3 exhibits a purely preference bias, and</li><li>Candidate-Elimination purely restriction bias.</li></ul><h2 id=why-prefer-short-hypotheses>Why prefer Short Hypotheses</h2><ul><li><strong>Occam&rsquo;s razor</strong>: Prefer the simplest hypothesis that fits the data.</li><li>Why? (Argument in Favor)<ul><li>One argument is that because there are fewer short hypotheses than long ones, it is less likely that one will find a short hypothesis that coincidentally fits the training data.</li><li>In contrast there are often many very complex hypotheses that fit the current training data but fail to generalize correctly to subsequent data.</li></ul></li><li>Argument Opposed<ul><li>There are many ways to define small sets of hypothesis</li></ul></li></ul><h2 id=issues>Issues</h2></div><hr><footer><main><a href=https://github.com/utsavdarlami/blogs/issues/new>Raise issues for Discussion on this post..</a></main></footer><p style=font-size:1.25em;text-align:center><a href=/blogs/notes/2021-05-30-08-53-22z-gradient/>&#8678;</a>
<a href=/blogs/notes/2021-06-03-11-07-01z-inductive_bias/>&#8680;</a></p></article><div class=bl-section><h4>Links to this note</h4><div class=backlinks><ul><li><a href=/blogs/notes/2021-05-26-11-31-31z-neural_network/>neural network</a></li></ul></div></div></main><footer></footer></body></html>