<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Recurrent Neural Networks</title><meta name=description content="felladog"><meta name=author content="Utsav Darlami"><link rel="shortcut icon" href=/blogs/img/21-512.png><link rel=stylesheet href=/blogs/css/style.css><link rel=stylesheet href=/blogs/css/syntax.css><link rel=stylesheet href=/blogs/css/toc.css><link rel=stylesheet href=/blogs/katex/katex.min.css><script defer src=/blogs/katex/katex.min.js></script>
<script defer src=/blogs/katex/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script></head><body><header></header><main><div class=toc><nav id=TableOfContents><ul><li><a href=#pytorch-implementation>Pytorch Implementation</a></li><li><a href=#summary>Summary</a></li></ul></nav><a href=# class=back-to-top>Back to top</a></div><script src=https://utsavdarlami.github.io/blogs/js/libs/jquery/3.3.1/jquery.slim.min.js></script>
<script>(function(){var t,e=$("#TableOfContents");if(e.length>0){t=$(window);function n(){var n,o=t.scrollTop(),i=$(".body h1, .body h2, .body h3, .body h4, .body h5, .body h6"),s="";if(i.each(function(e,t){t=$(t),t.offset().top-10<=o&&(s=t.attr("id"))}),n=e.find("a.current"),n.length==1&&n.eq(0).attr("href")=="#"+s)return!0;n.each(function(e,t){$(t).removeClass("current").siblings("ul").hide()}),e.find('a[href="#'+s+'"]').parentsUntil("#TableOfContents").each(function(e,t){$(t).children("a").addClass("current").siblings("ul").show()})}t.on("scroll",n),$(document).ready(function(){e.find("a").parent("li").find("ul").hide(),n(),document.getElementsByClassName("toc")[0].style.display=""})}})()</script><p align=right><a href=https://utsavdarlami.github.io/blogs/about>Me</a> |
<a href=https://utsavdarlami.github.io/blogs/>blogs</a> |
<a href=https://utsavdarlami.github.io/blogs/notes>notes</a> |
<a href=https://utsavdarlami.github.io/blogs/tags>tags</a> |
<a href=https://utsavdarlami.github.io/blogs/categories>categories</a> |
<a href=https://utsavdarlami.github.io/blogs/index.xml>feed</a>
<a href=https://utsavdarlami.github.io/>home</a> |</p><article><h1>Recurrent Neural Networks</h1><div style=float:left><time>Created Date : 2021 March 02</time></div><br><div style=float:left><time>Last Modified : 2021 September 13</time></div><hr><div>tags:
<a href=/tags/rnn>RNN</a>
<a href=/tags/sequence-models>Sequence Models</a></div><div style=float:left>categories:
<a href=/categories/deep-learning>Deep Learning</a></div><div><hr><ul><li>Acknowledgement<ul><li><p><a href=https://d2l.ai/chapter%5Frecurrent-neural-networks/index.html>https://d2l.ai/chapter%5Frecurrent-neural-networks/index.html</a></p></li><li><p><a href=https://github.com/fastai/fastbook/blob/master/12%5Fnlp%5Fdive.ipynb>https://github.com/fastai/fastbook/blob/master/12%5Fnlp%5Fdive.ipynb</a></p></li><li><p><a href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks>https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks</a></p></li><li><p><a href=https://colah.github.io/posts/2015-08-Understanding-LSTMs/>https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a> [Mainly LSTM]</p></li><li><p><a href=https://deeplearning.cs.cmu.edu/S20/document/recitation/recitation-7.pdf>https://deeplearning.cs.cmu.edu/S20/document/recitation/recitation-7.pdf</a></p></li><li><p><a href=http://cs231n.stanford.edu/slides/2017/cs231n%5F2017%5Flecture10.pdf>http://cs231n.stanford.edu/slides/2017/cs231n%5F2017%5Flecture10.pdf</a></p></li><li><p><a href="https://www.youtube.com/watch?v=6niqTuYFZLQ">https://www.youtube.com/watch?v=6niqTuYFZLQ</a></p></li><li><p><a href=https://github.com/fastai/fastbook/blob/master/12%5Fnlp%5Fdive.ipynb>https://github.com/fastai/fastbook/blob/master/12%5Fnlp%5Fdive.ipynb</a> [ fast ai nlp dive rnn archi]</p></li><li><p><a href=http://ethen8181.github.io/machine-learning/deep%5Flearning/rnn/1%5Fpytorch%5Frnn.html#Recurrent-Neural-Network-(RNN)>http://ethen8181.github.io/machine-learning/deep%5Flearning/rnn/1%5Fpytorch%5Frnn.html#Recurrent-Neural-Network-(RNN)</a> [Main reference]</p></li><li><p><a href=https://medium.com/ecovisioneth/building-deep-multi-layer-recurrent-neural-networks-with-star-cell-2f01acdb73a7>https://medium.com/ecovisioneth/building-deep-multi-layer-recurrent-neural-networks-with-star-cell-2f01acdb73a7</a> [Multi Layer]</p></li><li><p><a href=https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677>https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677</a></p></li><li><p><a href=https://www.jeremyjordan.me/introduction-to-recurrent-neural-networks/>https://www.jeremyjordan.me/introduction-to-recurrent-neural-networks/</a></p></li><li><p><a href=https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677>https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677</a></p></li><li><p><a href=https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L19/character-rnn/01%5Fchar-rnn%5Flstmcell-ver.ipynb>Sebastian Raschka Character Generation using lstm cell pytorch</a></p></li></ul></li></ul><hr><ul><li><p>Recurrent neural networks (RNNs) are designed to better handle sequential information. (text and stocks)</p></li><li><p>RNNs introduce state variables(hidden state) to store past information, together with the current inputs, to determine the current outputs.</p></li></ul><figure><img src=/blogs/ox-hugo/2021-06-03_18-21-51_screenshot.png alt="Figure 1: rnn vs nn" width=420 height=600><figcaption><p>Figure 1: rnn vs nn</p></figcaption></figure><figure><img src=/blogs/ox-hugo/rnn2.png alt="Figure 2: a folded rnn" width=700 height=550><figcaption><p>Figure 2: a folded rnn</p></figcaption></figure><figure><img src=/blogs/ox-hugo/rnn.png alt="Figure 3: a unfolded rnn" width=700 height=550><figcaption><p>Figure 3: a unfolded rnn</p></figcaption></figure><ul><li>Internal State of RNN</li></ul><figure><img src=/blogs/ox-hugo/my_internal.png alt="Figure 4: a state diagram," width=700 height=550><figcaption><p>Figure 4: a state diagram,</p></figcaption></figure><h2 id=pytorch-implementation>Pytorch Implementation</h2><h2 id=summary>Summary</h2></div><p style=font-size:1.65em;text-align:center><a href=/blogs/posts/2021-02-28--11-34-36z--blog_using_org_and_hugo/>&#8678;</a>
<a href=/blogs/notes/2021-03-06--02-21-33z--batch_normalization/>&#8680;</a></p><hr><div class=bl-section><h4>Links to this note</h4><div class=backlinks><ul><li><a href=/blogs/notes/2021-05-26--11-31-31z--neural_network/>neural network</a></li></ul></div></div><hr><footer><main><h3>Comments</h3><script src=https://utteranc.es/client.js repo=utsavdarlami/blogs issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></main></footer></article></main><footer></footer></body></html>