<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>ML Model Evaluation</title><meta name=description content="felladog"><meta name=author content="Utsav Darlami"><link rel="shortcut icon" href=/blogs/img/21-512.png><link rel=stylesheet href=/blogs/css/style.css><link rel=stylesheet href=/blogs/css/syntax.css><link rel=stylesheet href=/blogs/css/toc.css><link rel=stylesheet href=/blogs/katex/katex.min.css><script defer src=/blogs/katex/katex.min.js></script><script defer src=/blogs/katex/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script></head><body><header></header><main><div class=toc><nav id=TableOfContents><ul><li><a href=#classfication>Classfication</a><ul><li><a href=#accuracy>Accuracy</a></li><li><a href=#precision>Precision</a></li><li><a href=#recall>Recall</a></li><li><a href=#f1-score>F1 Score</a></li><li><a href=#dice-score>Dice Score</a></li><li><a href=#confusion-matrix>Confusion Matrix</a></li></ul></li></ul></nav><a href=# class=back-to-top>Back to top</a></div><script src=https://utsavdarlami.github.io/blogs/js/libs/jquery/3.3.1/jquery.slim.min.js></script><script>(function(){var a=$('#TableOfContents'),b;if(a.length>0){b=$(window);function c(){var e=b.scrollTop(),f=$('.body h1, .body h2, .body h3, .body h4, .body h5, .body h6'),c="",d;if(f.each(function(b,a){a=$(a),a.offset().top-10<=e&&(c=a.attr('id'))}),d=a.find('a.current'),d.length==1&&d.eq(0).attr('href')=='#'+c)return!0;d.each(function(b,a){$(a).removeClass('current').siblings('ul').hide()}),a.find('a[href="#'+c+'"]').parentsUntil('#TableOfContents').each(function(b,a){$(a).children('a').addClass('current').siblings('ul').show()})}b.on('scroll',c),$(document).ready(function(){a.find('a').parent('li').find('ul').hide(),c(),document.getElementsByClassName('toc')[0].style.display=''})}})()</script><p align=right><a href=https://utsavdarlami.github.io/>home</a> |
<a href=https://utsavdarlami.github.io/blogs/>blogs</a> |
<a href=https://utsavdarlami.github.io/blogs/notes>notes</a> |
<a href=https://utsavdarlami.github.io/blogs/about>about me</a> |
<a href=https://utsavdarlami.github.io/blogs/tags>tags</a> |
<a href=https://utsavdarlami.github.io/blogs/categories>categories</a> |
<a href=https://utsavdarlami.github.io/blogs/index.xml>feed</a></p><article><h1>ML Model Evaluation</h1><div style=float:left><time>Created Date : 2021 February 24</time></div><br><div style=float:left><time>Last Modified : 2021 July 08</time></div><hr><div>tags:
<a href=/blogs/tags/f1-score>f1 score</a>
<a href=/blogs/tags/dice-score>dice score</a>
<a href=/blogs/tags/precision>precision</a>
<a href=/blogs/tags/recall>recall</a></div><div style=float:left>categories:
<a href=/blogs/categories/machine-learning>Machine Learning</a></div><div><hr><ul><li>references<ul><li>To Read:<ul><li><a href=https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28>https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28</a></li></ul></li></ul></li><li>questions</li></ul><hr><p><a href=/blogs/notes/20210119123811-machine_learning/>ml</a> model evaluation methods</p><h2 id=classfication>Classfication</h2><h3 id=accuracy>Accuracy</h3><h3 id=precision>Precision</h3><ul><li>Precision = \(\frac{True Positive}{True Positive + False Positive}\)</li><li>From all the postive prediction given by our hypothesis/model how many examples where true positive</li></ul><h3 id=recall>Recall</h3><ul><li>Recall = \(\frac{True Positive}{True Positive + False Negative}\)</li><li>From all the postive examples how many examples where correctly classified by our hypothesis/model</li></ul><h3 id=f1-score>F1 Score</h3><ul><li><p>A harmonic mean between recall and precision</p><ul><li>Why ?<ul><li>Tries to give the lowest value between recall and precision</li><li>biased to the lowest value</li><li>Balances recall and precision</li></ul></li></ul></li><li><p>F1 Score = \(\frac{2}{\frac{1}{Precision} + \frac{1}{Recall}}\)</p></li><li><p>From Wikipedia</p><ul><li><em>In information retrieval and machine learning, the harmonic mean of the precision and the recall is often used as an aggregated performance score for the evaluation of algorithms and systems: the F-score (or F-measure). This is used in information retrieval because only the positive class is of relevance, while number of negatives, in general, is large and unknown.[14] It is thus a trade-off as to whether the correct positive predictions should be measured in relation to the number of predicted positives or the number of real positives, so it is measured versus a putative number of positives that is an arithmetic mean of the two possible denominators.</em></li></ul></li></ul><h3 id=dice-score>Dice Score</h3><ul><li><p>It is F1 Score</p></li><li><p>Dice Score = \(\frac{2 * Intersection}{Union + Intersection}\)</p><p>= \(\frac{2*TP}{2*TP + FP + FN}\)</p></li><li><p>For Image Segmentaion evaluation</p></li></ul><h3 id=confusion-matrix>Confusion Matrix</h3><ul><li>The scikit learn confusion matrix representation will be a bit different, as scikit learn considers<ul><li>the actual target classes as columns</li><li>the predicted classes as rows,</li></ul></li></ul><figure><img src=/blogs/ox-hugo/cf_matrix.png width=450 height=250></figure></div><p style=font-size:1.65em;text-align:center><a href=/blogs/notes/20210119123811-machine_learning/>&#8678;</a>
<a href=/blogs/posts/2021-02-28-11-34-36z-blog_using_org_and_hugo/>&#8680;</a></p><hr><div class=bl-section><h4>Links to this note</h4><div class=backlinks><ul><li><a href=/blogs/notes/20210119123811-machine_learning/>machine learning</a></li></ul></div></div><hr><footer><main><h3>Comments</h3><script src=https://utteranc.es/client.js repo=utsavdarlami/blogs issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></main></footer></article></main><footer></footer></body></html>