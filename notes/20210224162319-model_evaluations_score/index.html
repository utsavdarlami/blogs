<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>ML Model Evaluation</title><meta name=description content="felladog"><meta name=author content="Utsav Darlami"><link rel="shortcut icon" href=/blogs/img/21-512.png><link rel=stylesheet href=/blogs/css/style.css><link rel=stylesheet href=/blogs/css/syntax.css><link rel=stylesheet href=/blogs/css/toc.css><link rel=stylesheet href=/blogs/katex/katex.min.css><script defer src=/blogs/katex/katex.min.js></script>
<script defer src=/blogs/katex/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script></head><body><header></header><main><div class=toc><nav id=TableOfContents><ul><li><a href=#classfication>Classfication</a><ul><li><a href=#true-positive--tp>True Positive (TP)</a></li><li><a href=#false-negative--fn>False Negative (FN)</a></li><li><a href=#false-positive--fp>False Positive (FP)</a></li><li><a href=#true-negative--tn>True Negative (TN)</a></li><li><a href=#accuracy>Accuracy</a></li><li><a href=#precision>Precision</a></li><li><a href=#recall>Recall</a></li><li><a href=#f1-score>F1 Score</a></li><li><a href=#dice-score>Dice Score</a></li><li><a href=#confusion-matrix>Confusion Matrix</a></li><li><a href=#classfication-report>Classfication Report</a></li></ul></li></ul></nav><a href=# class=back-to-top>Back to top</a></div><script src=https://utsavdarlami.github.io/blogs/js/libs/jquery/3.3.1/jquery.slim.min.js></script>
<script>(function(){var t,e=$("#TableOfContents");if(e.length>0){t=$(window);function n(){var n,o=t.scrollTop(),i=$(".body h1, .body h2, .body h3, .body h4, .body h5, .body h6"),s="";if(i.each(function(e,t){t=$(t),t.offset().top-10<=o&&(s=t.attr("id"))}),n=e.find("a.current"),n.length==1&&n.eq(0).attr("href")=="#"+s)return!0;n.each(function(e,t){$(t).removeClass("current").siblings("ul").hide()}),e.find('a[href="#'+s+'"]').parentsUntil("#TableOfContents").each(function(e,t){$(t).children("a").addClass("current").siblings("ul").show()})}t.on("scroll",n),$(document).ready(function(){e.find("a").parent("li").find("ul").hide(),n(),document.getElementsByClassName("toc")[0].style.display=""})}})()</script><p align=right><a href=https://utsavdarlami.github.io/blogs/about>Me</a> |
<a href=https://utsavdarlami.github.io/blogs/>blogs</a> |
<a href=https://utsavdarlami.github.io/blogs/notes>notes</a> |
<a href=https://utsavdarlami.github.io/blogs/tags>tags</a> |
<a href=https://utsavdarlami.github.io/blogs/categories>categories</a> |
<a href=https://utsavdarlami.github.io/blogs/index.xml>feed</a>
<a href=https://utsavdarlami.github.io/>home</a> |</p><article><h1>ML Model Evaluation</h1><div style=float:left><time>Created Date : 2021 February 24</time></div><br><div style=float:left><time>Last Modified : 2022 February 06</time></div><hr><div>tags:
<a href=/tags/accuracy>accuracy</a>
<a href=/tags/f1-score>f1 score</a>
<a href=/tags/dice-score>dice score</a>
<a href=/tags/precision>precision</a>
<a href=/tags/recall>recall</a></div><div style=float:left>categories:
<a href=/categories/machine-learning>Machine Learning</a></div><div><hr><ul><li>references<ul><li>To Read:<ul><li><a href=https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28>https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28</a></li><li><a href=https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin>https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin</a></li></ul></li></ul></li><li>questions</li></ul><hr><p><a href=/blogs/404.html>ml</a> model evaluation methods</p><h2 id=classfication>Classfication</h2><h3 id=true-positive--tp>True Positive (TP)</h3><ul><li>Positive class correctly labeled/predicted</li></ul><h3 id=false-negative--fn>False Negative (FN)</h3><ul><li>Positive class incorrectly labeled/predicted</li></ul><h3 id=false-positive--fp>False Positive (FP)</h3><ul><li>Negative class incorrectly labeled/predicted</li></ul><h3 id=true-negative--tn>True Negative (TN)</h3><ul><li>Negative class correctly labeled/predicted</li></ul><h3 id=accuracy>Accuracy</h3><ul><li>It is simply a ratio of correctly predicted observation to the total observations.</li><li>Accuracy = \(\frac{TP + TN}{TP + TN + FN + FP}\)</li></ul><h3 id=precision>Precision</h3><ul><li>Precision = \(\frac{True Positive}{True Positive + False Positive}\)</li><li>From all the postive prediction given by our hypothesis/model how many examples were true positive</li></ul><h3 id=recall>Recall</h3><ul><li>Recall = \(\frac{True Positive}{True Positive + False Negative}\)</li><li>From all the postive examples how many examples were correctly classified by our hypothesis/model</li></ul><h3 id=f1-score>F1 Score</h3><ul><li><p>A harmonic mean between recall and precision</p><ul><li>Why ?<ul><li>Tries to give the lowest value between recall and precision</li><li>biased to the lowest value</li><li>Balances recall and precision</li></ul></li></ul></li><li><p>F1 Score = \(\frac{2}{\frac{1}{Precision} + \frac{1}{Recall}}\)</p></li><li><p>From Wikipedia</p><ul><li><em>In information retrieval and machine learning, the harmonic mean of the precision and the recall is often used as an aggregated performance score for the evaluation of algorithms and systems: the F-score (or F-measure). This is used in information retrieval because only the positive class is of relevance, while number of negatives, in general, is large and unknown.[14] It is thus a trade-off as to whether the correct positive predictions should be measured in relation to the number of predicted positives or the number of real positives, so it is measured versus a putative number of positives that is an arithmetic mean of the two possible denominators.</em></li></ul></li></ul><h3 id=dice-score>Dice Score</h3><ul><li><p>It is F1 Score</p></li><li><p>Dice Score = \(\frac{2 * Intersection}{Union + Intersection}\)</p><p>= \(\frac{2*TP}{2*TP + FP + FN}\)</p></li><li><p>For Image Segmentaion evaluation</p></li></ul><h3 id=confusion-matrix>Confusion Matrix</h3><ul><li>The scikit learn confusion matrix representation will be a bit different, as scikit learn considers<ul><li>the actual target classes as columns</li><li>the predicted classes as rows,</li></ul></li></ul><figure><img src=/blogs/ox-hugo/cf_matrix.png width=450 height=250></figure><h3 id=classfication-report>Classfication Report</h3><ul><li>It shows a representation of the main classification metrics on a per-class basis.</li><li>The classification report displays the precision, recall, F1, and support scores for the model.</li><li>These metrics are defined in terms of true and false positives, and true and false negatives.</li></ul></div><p style=font-size:1.65em;text-align:center><a href=/blogs/notes/20210224161655-image_segmentation/>&#8678;</a>
<a href=/blogs/posts/2021-02-28--11-34-36z--blog_using_org_and_hugo/>&#8680;</a></p><hr><div class=bl-section><h4>Links to this note</h4><div class=backlinks><ul><li><a href=/blogs/notes/20210224161655-image_segmentation/>image segmentation</a></li><li><a href=/blogs/notes/20210119123811-machine_learning/>machine learning</a></li></ul></div></div><hr><footer><main><h3>Comments</h3><script src=https://utteranc.es/client.js repo=utsavdarlami/blogs issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></main></footer></article></main><footer></footer></body></html>