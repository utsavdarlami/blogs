<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ml on felladog</title><link>https://utsavdarlami.github.io/blogs/tags/ml/</link><description>Recent content in ml on felladog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 26 May 2021 17:16:00 +0545</lastBuildDate><atom:link href="https://utsavdarlami.github.io/blogs/tags/ml/index.xml" rel="self" type="application/rss+xml"/><item><title>perceptron</title><link>https://utsavdarlami.github.io/blogs/notes/20210224173929-perceptron/</link><pubDate>Wed, 26 May 2021 17:16:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/20210224173929-perceptron/</guid><description>References :
Done Reading: Sebastian Raschka Perceptron Lecture Slide Reading: Tom Mitchell Lectures slides of chapter 4 Tom Mitchell, Machine Learning Chapter 4 To Read: https://www.wikiwand.com/en/Perceptron Questions :
A learning rule for the computational/mathematical neuron model Rosenblatt, F. (1957). The perceptron, a perceiving and recognizing automaton. Project Para. Cornell Aeronautical Laboratory Figure 1: A perceptron \(o(\overrightarrow{x}) = sgn(\overrightarrow{w} \cdot \overrightarrow{x})\) where, \( sgn(y) = \begin{cases} 1 &amp;amp; \text{if y &amp;gt; 0} \\ -1 &amp;amp; \text{otherwise} \end{cases} \) Space \(H\) of candidate hypotheses is \(H = \{ \overrightarrow{w} | \overrightarrow{w} \in \Re^{n+1} \}\) Representations A single layer perceptron can be used to represent many boolean functions AND \(w_{0}\) = -.</description></item><item><title>machine learning</title><link>https://utsavdarlami.github.io/blogs/notes/20210119123811-machine_learning/</link><pubDate>Sun, 17 Jan 2021 17:28:00 +0545</pubDate><guid>https://utsavdarlami.github.io/blogs/notes/20210119123811-machine_learning/</guid><description>references Reading https://www.cs.cmu.edu/~tom/mlbook.html To Read https://medium.com/octavian-ai/how-to-get-started-with-machine-learning-on-graphs-7f0795c83763 https://medium.datadriveninvestor.com/3-steps-introduction-to-machine-learning-and-design-of-a-learning-system-bd12b65aa50c https://chrisalbon.com/ A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.
A checkers learning problem: Task T: playing checkers Performance measure P: percent of games won against opponents Training experience E: playing practice games against itself Supervised Lecture 1: Supervised Learning regression classfication Unsupervised clustering dimensionality reduction ML Model Evaluation Graph Based Resources Pandas Guide , axis = https://stackoverflow.</description></item></channel></rss>